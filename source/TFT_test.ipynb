{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LayerNormalization, Add, Activation\n",
    "\n",
    "class GatedResidualNetwork(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, output_size=None, dropout_rate=0.1):\n",
    "        super(GatedResidualNetwork, self).__init__()\n",
    "        self.units = units\n",
    "        self.output_size = output_size if output_size else units\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.dense1 = Dense(self.units)\n",
    "        self.dense2 = Dense(self.output_size)\n",
    "        self.dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
    "        self.layer_norm = LayerNormalization()\n",
    "        self.gate = Dense(self.output_size, activation='sigmoid')\n",
    "        self.activation = Activation('elu')\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense2(x)\n",
    "        gate = self.gate(inputs)\n",
    "        return self.layer_norm(inputs + gate * x)\n",
    "class VariableSelectionNetwork(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_size, units, dropout_rate=0.1):\n",
    "        super(VariableSelectionNetwork, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.units = units\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.grn = GatedResidualNetwork(self.units, dropout_rate=self.dropout_rate)\n",
    "        self.dense = Dense(self.input_size, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        flattened_inputs = tf.concat([tf.expand_dims(i, axis=-1) for i in inputs], axis=-1)\n",
    "        grn_outputs = self.grn(flattened_inputs)\n",
    "        weights = self.dense(grn_outputs)\n",
    "        weighted_sum = tf.reduce_sum(grn_outputs * weights, axis=-1)\n",
    "        return weighted_sum\n",
    "class TemporalAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, num_heads, dropout_rate=0.1):\n",
    "        super(TemporalAttention, self).__init__()\n",
    "        self.units = units\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.multi_head_attention = tf.keras.layers.MultiHeadAttention(num_heads=self.num_heads, key_dim=self.units)\n",
    "        self.dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
    "        self.layer_norm = LayerNormalization()\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        attn_output = self.multi_head_attention(inputs, inputs)\n",
    "        attn_output = self.dropout(attn_output)\n",
    "        return self.layer_norm(inputs + attn_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer 'gated_residual_network_1' (type GatedResidualNetwork).\n\n{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} Incompatible shapes: [10,10,32] vs. [10,10,64] [Op:AddV2]\n\nCall arguments received by layer 'gated_residual_network_1' (type GatedResidualNetwork):\n  • inputs=tf.Tensor(shape=(10, 10, 32), dtype=float32)\n  • kwargs={'training': 'None'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m model \u001b[38;5;241m=\u001b[39m TemporalFusionTransformer(input_size, units, num_heads, output_size, dropout_rate)\n\u001b[1;32m     25\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal([\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m10\u001b[39m, input_size])  \u001b[38;5;66;03m# Batch size 32, sequence length 10, input size 10\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(outputs\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/anaconda3/envs/astro_py8/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m, in \u001b[0;36mTemporalFusionTransformer.call\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 12\u001b[0m     selected_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvsn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemporal_attention(selected_features)\n\u001b[1;32m     14\u001b[0m     grn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrn(attn_output)\n",
      "Cell \u001b[0;32mIn[1], line 39\u001b[0m, in \u001b[0;36mVariableSelectionNetwork.call\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     38\u001b[0m     flattened_inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat([tf\u001b[38;5;241m.\u001b[39mexpand_dims(i, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inputs], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m     grn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflattened_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(grn_outputs)\n\u001b[1;32m     41\u001b[0m     weighted_sum \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_sum(grn_outputs \u001b[38;5;241m*\u001b[39m weights, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 25\u001b[0m, in \u001b[0;36mGatedResidualNetwork.call\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense2(x)\n\u001b[1;32m     24\u001b[0m gate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate(inputs)\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m)\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'gated_residual_network_1' (type GatedResidualNetwork).\n\n{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} Incompatible shapes: [10,10,32] vs. [10,10,64] [Op:AddV2]\n\nCall arguments received by layer 'gated_residual_network_1' (type GatedResidualNetwork):\n  • inputs=tf.Tensor(shape=(10, 10, 32), dtype=float32)\n  • kwargs={'training': 'None'}"
     ]
    }
   ],
   "source": [
    "class TemporalFusionTransformer(tf.keras.Model):\n",
    "    def __init__(self, input_size, units, num_heads, output_size, dropout_rate=0.1):\n",
    "        super(TemporalFusionTransformer, self).__init__()\n",
    "        self.units = units\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.vsn = VariableSelectionNetwork(input_size, units, dropout_rate)\n",
    "        self.temporal_attention = TemporalAttention(units, num_heads, dropout_rate)\n",
    "        self.grn = GatedResidualNetwork(units, output_size, dropout_rate)\n",
    "        self.output_layer = Dense(output_size)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        selected_features = self.vsn(inputs)\n",
    "        attn_output = self.temporal_attention(selected_features)\n",
    "        grn_output = self.grn(attn_output)\n",
    "        return self.output_layer(grn_output)\n",
    "\n",
    "# Example usage\n",
    "input_size = 10\n",
    "units = 64\n",
    "num_heads = 4\n",
    "output_size = 1\n",
    "dropout_rate = 0.1\n",
    "\n",
    "model = TemporalFusionTransformer(input_size, units, num_heads, output_size, dropout_rate)\n",
    "inputs = tf.random.normal([32, 10, input_size])  # Batch size 32, sequence length 10, input size 10\n",
    "outputs = model(inputs)\n",
    "print(outputs.shape)  # Expected output shape: (32, 10, output_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astro_py8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
